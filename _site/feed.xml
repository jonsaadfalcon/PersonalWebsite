<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-12-02T22:31:18-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Jon Saad-Falcon</title><author><name>Jon Saad-Falcon</name><email>jonsaadfalcon@gmail.com</email></author><entry><title type="html">ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction</title><link href="http://localhost:4000/papers/colbert_v2" rel="alternate" type="text/html" title="ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction" /><published>2021-12-02T00:00:00-05:00</published><updated>2021-12-02T00:00:00-05:00</updated><id>http://localhost:4000/papers/colbert_v2</id><content type="html" xml:base="http://localhost:4000/papers/colbert_v2">&lt;p&gt;Neural information retrieval (IR) has greatly advanced search and other knowledge-intensive language tasks. While many neural IR methods encode queries and documents into single-vector representations, late interaction models produce multi-vector representations at the granularity of each token and decompose relevance modeling into scalable token-level computations. This decomposition has been shown to make late interaction more effective, but it inflates the space footprint of these models by an order of magnitude. In this work, we introduce ColBERTv2, a retriever that couples an aggressive residual compression mechanism with a denoised supervision strategy to simultaneously improve the quality and space footprint of late interaction. We evaluate ColBERTv2 across a wide range of benchmarks, establishing state-of-the-art quality within and outside the training domain while reducing the space footprint of late interaction models by 5–8×.&lt;/p&gt;</content><author><name>Keshav Santhanam*</name></author><summary type="html">Neural information retrieval (IR) has greatly advanced search and other knowledge-intensive language tasks. While many neural IR methods encode queries and documents into single-vector representations, late interaction models produce multi-vector representations at the granularity of each token and decompose relevance modeling into scalable token-level computations. This decomposition has been shown to make late interaction more effective, but it inflates the space footprint of these models by an order of magnitude. In this work, we introduce ColBERTv2, a retriever that couples an aggressive residual compression mechanism with a denoised supervision strategy to simultaneously improve the quality and space footprint of late interaction. We evaluate ColBERTv2 across a wide range of benchmarks, establishing state-of-the-art quality within and outside the training domain while reducing the space footprint of late interaction models by 5–8×.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/images/papers/ColBERTv2.png" /><media:content medium="image" url="http://localhost:4000/images/papers/ColBERTv2.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">A Search Engine for Discovery of Scientific Challenges and Directions</title><link href="http://localhost:4000/papers/search_engine" rel="alternate" type="text/html" title="A Search Engine for Discovery of Scientific Challenges and Directions" /><published>2021-08-31T00:00:00-04:00</published><updated>2021-08-31T00:00:00-04:00</updated><id>http://localhost:4000/papers/search_engine</id><content type="html" xml:base="http://localhost:4000/papers/search_engine">&lt;p&gt;Keeping track of scientific challenges, advances and emerging directions is a fundamental part of research. However, researchers face a flood of papers that hinders discovery of important knowledge. In biomedicine, this directly impacts human lives. To address this problem, we present a novel task of extraction and search of scientific challenges and directions, to facilitate rapid knowledge discovery. We construct and release an expert-annotated corpus of texts sampled from full-length papers, labeled with novel semantic categories that generalize across many types of challenges and directions. We focus on a large corpus of interdisciplinary work relating to the COVID-19 pandemic, ranging from biomedicine to areas such as AI and economics. We apply a model trained on our data to identify challenges and directions across the corpus and build a dedicated search engine. In experiments with 19 researchers and clinicians using our system, we outperform a popular scientific search engine in assisting knowledge discovery. Finally, we show that models trained on our resource generalize to the wider biomedical domain and to AI papers, highlighting its broad utility. We make our data, model and search engine publicly available.&lt;/p&gt;</content><author><name>Dan Lahav</name></author><summary type="html">Keeping track of scientific challenges, advances and emerging directions is a fundamental part of research. However, researchers face a flood of papers that hinders discovery of important knowledge. In biomedicine, this directly impacts human lives. To address this problem, we present a novel task of extraction and search of scientific challenges and directions, to facilitate rapid knowledge discovery. We construct and release an expert-annotated corpus of texts sampled from full-length papers, labeled with novel semantic categories that generalize across many types of challenges and directions. We focus on a large corpus of interdisciplinary work relating to the COVID-19 pandemic, ranging from biomedicine to areas such as AI and economics. We apply a model trained on our data to identify challenges and directions across the corpus and build a dedicated search engine. In experiments with 19 researchers and clinicians using our system, we outperform a popular scientific search engine in assisting knowledge discovery. Finally, we show that models trained on our resource generalize to the wider biomedical domain and to AI papers, highlighting its broad utility. We make our data, model and search engine publicly available.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/images/papers/search_engine.png" /><media:content medium="image" url="http://localhost:4000/images/papers/search_engine.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Argo Scholar: Interactive Visual Exploration of Literature in Browsers</title><link href="http://localhost:4000/papers/argo-scholar" rel="alternate" type="text/html" title="Argo Scholar: Interactive Visual Exploration of Literature in Browsers" /><published>2021-07-27T00:00:00-04:00</published><updated>2021-07-27T00:00:00-04:00</updated><id>http://localhost:4000/papers/argo-scholar</id><content type="html" xml:base="http://localhost:4000/papers/argo-scholar">&lt;p&gt;Discovering and making sense of relevant research literature is fundamental to becoming knowledgeable in any scientific discipline. Visualization can aid this process; however, existing tools’ adoption and impact have often been constrained, such as by their reliance on small curated paper datasets that quickly become outdated or a lack of support for personalized exploration. We introduce Argo Scholar, an open-source, web-based visualization tool for interactive exploration of literature and easy sharing of exploration results. ARGO SCHOLAR queries and visualizes Semantic Scholar’s live data of almost 200 million papers, enabling users to generate personalized literature exploration results in real-time through flexible, incremental exploration, a common and effective method for researchers to discover relevant work. Our tool allows users to easily share their literature exploration results as a URL or web-embedded IFrame application. Argo Scholar is open-sourced and available at https://poloclub.github.io/argo-scholar/&lt;/p&gt;</content><author><name>Kevin Li</name></author><summary type="html">Discovering and making sense of relevant research literature is fundamental to becoming knowledgeable in any scientific discipline. Visualization can aid this process; however, existing tools’ adoption and impact have often been constrained, such as by their reliance on small curated paper datasets that quickly become outdated or a lack of support for personalized exploration. We introduce Argo Scholar, an open-source, web-based visualization tool for interactive exploration of literature and easy sharing of exploration results. ARGO SCHOLAR queries and visualizes Semantic Scholar’s live data of almost 200 million papers, enabling users to generate personalized literature exploration results in real-time through flexible, incremental exploration, a common and effective method for researchers to discover relevant work. Our tool allows users to easily share their literature exploration results as a URL or web-embedded IFrame application. Argo Scholar is open-sourced and available at https://poloclub.github.io/argo-scholar/</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/images/papers/argo_scholar.png" /><media:content medium="image" url="http://localhost:4000/images/papers/argo_scholar.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Large-Scale Analysis of Career Transitions: The Impact of Human Capital, Job History, and Language Factors</title><link href="http://localhost:4000/papers/human_capital" rel="alternate" type="text/html" title="Large-Scale Analysis of Career Transitions: The Impact of Human Capital, Job History, and Language Factors" /><published>2021-06-15T00:00:00-04:00</published><updated>2021-06-15T00:00:00-04:00</updated><id>http://localhost:4000/papers/human_capital</id><content type="html" xml:base="http://localhost:4000/papers/human_capital">&lt;p&gt;As job markets worldwide have become more competitive and applicant selection criteria have become more opaque, and different (and sometimes contradictory) information and advice is available for job seekers wishing to progress in their careers, it has never been more difficult to determine which factors in a résumé most effectively help career progression. In this work we present a novel, large scale dataset of over half a million résumés with preliminary analysis to begin to answer empirically which factors help or hurt people wishing to transition to more senior roles as they progress in their career. We find that previous experience forms the most important factor, outweighing other aspects of human capital, and find which language factors in a résumé have significant effects. This lays the groundwork for future inquiry in career trajectories using large scale data analysis and natural language processing techniques.&lt;/p&gt;</content><author><name>Austin P Wright</name></author><summary type="html">As job markets worldwide have become more competitive and applicant selection criteria have become more opaque, and different (and sometimes contradictory) information and advice is available for job seekers wishing to progress in their careers, it has never been more difficult to determine which factors in a résumé most effectively help career progression. In this work we present a novel, large scale dataset of over half a million résumés with preliminary analysis to begin to answer empirically which factors help or hurt people wishing to transition to more senior roles as they progress in their career. We find that previous experience forms the most important factor, outweighing other aspects of human capital, and find which language factors in a résumé have significant effects. This lays the groundwork for future inquiry in career trajectories using large scale data analysis and natural language processing techniques.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/images/papers/human_capital.png" /><media:content medium="image" url="http://localhost:4000/images/papers/human_capital.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">EnergyVis: Interactively Tracking and Exploring Energy Consumption for ML Models</title><link href="http://localhost:4000/papers/energy-vis" rel="alternate" type="text/html" title="EnergyVis: Interactively Tracking and Exploring Energy Consumption for ML Models" /><published>2021-05-06T00:00:00-04:00</published><updated>2021-05-06T00:00:00-04:00</updated><id>http://localhost:4000/papers/energyvis</id><content type="html" xml:base="http://localhost:4000/papers/energy-vis">&lt;p&gt;The advent of larger machine learning (ML) models have improved state-of-the-art (SOTA) performance in various modeling tasks, ranging from computer vision to natural language. As ML models continue increasing in size, so does their respective energy consumption and computational requirements. However, the methods for tracking, reporting, and comparing energy consumption remain limited. We presentEnergyVis, an interactive energy consumption tracker for ML models. Consisting of multiple coordinated views, EnergyVis enables researchers to interactively track, visualize and compare model energy consumption across key energy consumption and carbon footprint metrics (kWh and CO2), helping users explore alternative deployment locations and hardware that may reduce carbon footprints. EnergyVis aims to raise awareness concerning computational sustainability by interactively highlighting excessive energy usage during model training; and by providing alternative training options to reduce energy usage.&lt;/p&gt;</content><author><name>Omar Shaikh</name></author><summary type="html">The advent of larger machine learning (ML) models have improved state-of-the-art (SOTA) performance in various modeling tasks, ranging from computer vision to natural language. As ML models continue increasing in size, so does their respective energy consumption and computational requirements. However, the methods for tracking, reporting, and comparing energy consumption remain limited. We presentEnergyVis, an interactive energy consumption tracker for ML models. Consisting of multiple coordinated views, EnergyVis enables researchers to interactively track, visualize and compare model energy consumption across key energy consumption and carbon footprint metrics (kWh and CO2), helping users explore alternative deployment locations and hardware that may reduce carbon footprints. EnergyVis aims to raise awareness concerning computational sustainability by interactively highlighting excessive energy usage during model training; and by providing alternative training options to reduce energy usage.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/images/papers/21-energyvis-map.png" /><media:content medium="image" url="http://localhost:4000/images/papers/21-energyvis-map.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Examining the Ordering of Rhetorical Strategies in Persuasive Requests</title><link href="http://localhost:4000/papers/persuasive-orderings" rel="alternate" type="text/html" title="Examining the Ordering of Rhetorical Strategies in Persuasive Requests" /><published>2020-11-28T00:00:00-05:00</published><updated>2020-11-28T00:00:00-05:00</updated><id>http://localhost:4000/papers/persuasive-orderings</id><content type="html" xml:base="http://localhost:4000/papers/persuasive-orderings">&lt;p&gt;Interpreting how persuasive language influences audiences has implications across many domains like advertising, argumentation, and propaganda. Persuasion relies on more than a message’s content. Arranging the order of the message itself (i.e., ordering specific rhetorical strategies) also plays an important role. To examine how strategy orderings contribute to persuasiveness, we first utilize a Variational Autoencoder model to disentangle content and rhetorical strategies in textual requests from a large-scale loan request corpus. We then visualize interplay between content and strategy through an attentional LSTM that predicts the success of textual requests. We find that specific (orderings of) strategies interact uniquely with a request’s content to impact success rate, and thus the persuasiveness of a request.&lt;/p&gt;</content><author><name>Omar Shaikh</name></author><summary type="html">Interpreting how persuasive language influences audiences has implications across many domains like advertising, argumentation, and propaganda. Persuasion relies on more than a message’s content. Arranging the order of the message itself (i.e., ordering specific rhetorical strategies) also plays an important role. To examine how strategy orderings contribute to persuasiveness, we first utilize a Variational Autoencoder model to disentangle content and rhetorical strategies in textual requests from a large-scale loan request corpus. We then visualize interplay between content and strategy through an attentional LSTM that predicts the success of textual requests. We find that specific (orderings of) strategies interact uniquely with a request’s content to impact success rate, and thus the persuasiveness of a request.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/images/featured/20-persuasion-strat.png" /><media:content medium="image" url="http://localhost:4000/images/featured/20-persuasion-strat.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Mapping Researchers with PeopleMap</title><link href="http://localhost:4000/papers/people-map" rel="alternate" type="text/html" title="Mapping Researchers with PeopleMap" /><published>2020-09-09T00:00:00-04:00</published><updated>2020-09-09T00:00:00-04:00</updated><id>http://localhost:4000/papers/people-map</id><content type="html" xml:base="http://localhost:4000/papers/people-map">&lt;p&gt;Discovering research expertise at universities can be a difficult task.
Directories routinely become outdated, and few help in visually
summarizing researchers’ work or supporting the exploration of
shared interests among researchers. This results in lost opportunities
for both internal and external entities to discover new connections,
nurture research collaboration, and explore the diversity of research.
To address this problem, at Georgia Tech, we have been developing PeopleMap, an open-source interactive web-based tool that
uses natural language processing (NLP) to create visual maps for
researchers based on their research interests and publications. Requiring only the researchers’ Google Scholar profiles as input, PeopleMap generates and visualizes embeddings for the researchers,
significantly reducing the need for manual curation of publication information. To encourage and facilitate easy adoption and extension
of PeopleMap, we have open-sourced it under the permissive MIT. PeopleMap has received positive feedback and enthusiasm for expanding its adoption across Georgia Tech.&lt;/p&gt;</content><author><name>Jon Saad-Falcon</name></author><summary type="html">Discovering research expertise at universities can be a difficult task. Directories routinely become outdated, and few help in visually summarizing researchers’ work or supporting the exploration of shared interests among researchers. This results in lost opportunities for both internal and external entities to discover new connections, nurture research collaboration, and explore the diversity of research. To address this problem, at Georgia Tech, we have been developing PeopleMap, an open-source interactive web-based tool that uses natural language processing (NLP) to create visual maps for researchers based on their research interests and publications. Requiring only the researchers’ Google Scholar profiles as input, PeopleMap generates and visualizes embeddings for the researchers, significantly reducing the need for manual curation of publication information. To encourage and facilitate easy adoption and extension of PeopleMap, we have open-sourced it under the permissive MIT. PeopleMap has received positive feedback and enthusiasm for expanding its adoption across Georgia Tech.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/images/papers/20-peoplemap.png" /><media:content medium="image" url="http://localhost:4000/images/papers/20-peoplemap.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>